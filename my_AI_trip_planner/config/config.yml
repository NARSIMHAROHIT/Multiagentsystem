llm:
  openai:
    provider: "openai"
    model_name: "gpt-3.5-turbo"
    temperature: 0.7
    max_tokens: 1500
  groq:
    provider: "groq"
    model_name: "llama-3.1-70b-versatile"
    temperature: 0.7
    max_tokens: 1500             